{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39167d49",
   "metadata": {},
   "source": [
    "---\n",
    "title: segmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3511c2b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "---\n",
    "title: Implémentation de classifieurs binaires \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb58355",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcce3fb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import parallel_backend\n",
    "parallel_backend(\"loky\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d84d5",
   "metadata": {
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from get_dataset import dataset_loaders\n",
    "dataset = list(dataset_loaders.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29a239",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dataset = \"segmentation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886ad7a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from get_dataset import load_dataset\n",
    "\n",
    "X, y = load_dataset(dataset)\n",
    "\n",
    "models = dict()\n",
    "\n",
    "def store_results(name, grid):\n",
    "    models[name] = {\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"best_estimator\": grid.best_estimator_,\n",
    "    }\n",
    "     \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78476681",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Data presentation\n",
    "\n",
    "**{eval}`dataset`\\** dataset contains `n` = {eval}`X.shape[0]` samples and `p` = {eval}`X.shape[1]` features.\n",
    "\n",
    "The target variable is binary and {}`y.mean() * 100:.2f`% of the samples are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bf9bb9a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize data using only the training set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a1daed",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Entraînement des classifieurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28402179",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Classifieurs non paramétriques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8d4d7",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91e43472",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KNeighborsClassifier(weights='uniform', algorithm='auto')\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    refit=True\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "store_results('KNN', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8144c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Distance-Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40471d2a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(weights='distance', algorithm='auto')\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    refit=True\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "store_results('KNN Distance Weighted', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fb87a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Condensed Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f41159a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.utils.validation import validate_data\n",
    "\n",
    "class CondensedNearestNeighbourTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sampling_strategy = \"auto\", random_state = 42, n_neighbors = None, n_seeds_S = 1):\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.random_state = random_state\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_seeds_S = n_seeds_S\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # validate_data(X, y, accept_sparse=True, reset=True)\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # check_X_y(X, y)\n",
    "\n",
    "        if y is None:\n",
    "            return X\n",
    "        else:    \n",
    "          return CondensedNearestNeighbour(\n",
    "            sampling_strategy = self.sampling_strategy,\n",
    "            random_state = self.random_state,\n",
    "            n_neighbors = self.n_neighbors,\n",
    "            n_seeds_S = self.n_seeds_S\n",
    "          ).fit_resample(X, y)\n",
    "\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "# check_estimator(CondensedNearestNeighbourTransformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbe01a95",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    ('cnn', CondensedNearestNeighbourTransformer(sampling_strategy='auto', n_neighbors=3, n_seeds_S=1)),\n",
    "    ('knn', KNeighborsClassifier(weights='uniform', algorithm='auto'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'cnn__n_neighbors': [3, 5, 7, 9],\n",
    "    'knn__n_neighbors': [3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    refit=True\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "store_results('KNN Condensed Nearest Neighbor', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142be471",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Locally Adaptive KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12efde0c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LocallyAdaptiveKNN(KNeighborsClassifier):\n",
    "    def predict(self, X):\n",
    "        distances, indices = self.kneighbors(X)\n",
    "        predictions = []\n",
    "        for i, neighbors in enumerate(indices):\n",
    "            local_k = int(len(neighbors) / 2)  # Example of adapting k locally\n",
    "            local_knn = KNeighborsClassifier(n_neighbors=local_k)\n",
    "            local_knn.fit(self._fit_X[neighbors], self._y[neighbors])\n",
    "            predictions.append(local_knn.predict([X[i]])[0])\n",
    "        return predictions\n",
    "\n",
    "model = LocallyAdaptiveKNN(weights='uniform', algorithm='auto')\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    refit=True\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "store_results('KNN Locally Adaptive', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4e1f0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Classifieurs binaires non linéaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1156d3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### DecisionTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79571fd8",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "  'max_depth': [3, 5, 7, 9],\n",
    "  'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=model,\n",
    "  param_grid=param_grid, \n",
    "  cv=5, \n",
    "  scoring='accuracy',\n",
    "  refit=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "store_results('Decision Tree', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1683dcc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### RandomForest\n",
    "\n",
    "**Variantes:**\n",
    "- simple\n",
    "- cost-sensitive learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af008c58",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "  'n_estimators': [50, 100, 200],\n",
    "  'max_depth': [3, 5, 7, 9],\n",
    "  'min_samples_split': [2, 5, 10],\n",
    "  'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=model,\n",
    "  param_grid=param_grid, \n",
    "  cv=5, \n",
    "  scoring='accuracy',\n",
    "  refit=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "store_results('Random Forest', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7a940",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### AdaBoost\n",
    "\n",
    "**Variantes:**\n",
    "- simple\n",
    "- early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedd3cf",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "  'n_estimators': [50, 100, 200],\n",
    "  'learning_rate': [0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=model,\n",
    "  param_grid=param_grid, \n",
    "  cv=5, \n",
    "  scoring='accuracy',\n",
    "  refit=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "store_results('AdaBoost', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d9d93d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Classifieurs binaires paramétriques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf17c6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### SVM linéaire\n",
    "- One-class SVM pour gérer le déséquilibre des classes\n",
    "- Combiner avec des méthodes de sous/sur-échantillonnage (SMOTE, RandomUnderSampling)\n",
    "- Cost-sensitive SVM : Différentes pénalités C pour chaque classe\n",
    "- Ensemble de SVMs avec bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b7365",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# One-class SVM for handling class imbalance\n",
    "one_class_svm = OneClassSVM(gamma='auto')\n",
    "\n",
    "# SMOTE for oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# RandomUnderSampler for undersampling\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Cost-sensitive SVM with different penalties for each class\n",
    "cost_sensitive_svm = SVC(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Bagging ensemble of SVMs\n",
    "bagging_svm = BaggingClassifier(base_estimator=cost_sensitive_svm, n_estimators=10, random_state=42)\n",
    "\n",
    "# Create a pipeline with SMOTE, undersampling, and bagging SVM\n",
    "model = ImbPipeline([\n",
    "  ('smote', smote),\n",
    "  ('under', under_sampler),\n",
    "  ('svm', bagging_svm)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "  'svm__base_estimator__C': [0.1, 1, 10],\n",
    "  'svm__base_estimator__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=model,\n",
    "  param_grid=param_grid, \n",
    "  cv=5, \n",
    "  scoring='accuracy',\n",
    "  refit=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "store_results('AdaBoost', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96861b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Régression logistique\n",
    "- Régression logistique avec pénalisation élastique (combinaison L1/L2)\n",
    "- Cost-sensitive avec pondération des classes\n",
    "- Régression logistique polynomiale\n",
    "- Régression logistique avec sélection de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac9068",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Logistic Regression with elastic net penalty (L1/L2 combination)\n",
    "elastic_net_lr = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, random_state=42)\n",
    "\n",
    "# Cost-sensitive Logistic Regression with class weighting\n",
    "cost_sensitive_lr = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Polynomial Logistic Regression\n",
    "polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "polynomial_lr = Pipeline([\n",
    "  ('poly', polynomial_features),\n",
    "  ('logistic', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Logistic Regression with feature selection\n",
    "feature_selector = SelectFromModel(LogisticRegression(penalty='l1', solver='liblinear', random_state=42))\n",
    "selected_features_lr = Pipeline([\n",
    "  ('feature_selection', feature_selector),\n",
    "  ('logistic', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grids = {\n",
    "  'Elastic Net Logistic Regression': {\n",
    "    'logistic__C': [0.1, 1, 10],\n",
    "    'logistic__l1_ratio': [0.1, 0.5, 0.9]\n",
    "  },\n",
    "  'Cost Sensitive Logistic Regression': {\n",
    "    'logistic__C': [0.1, 1, 10]\n",
    "  },\n",
    "  'Polynomial Logistic Regression': {\n",
    "    'logistic__C': [0.1, 1, 10]\n",
    "  },\n",
    "  'Selected Features Logistic Regression': {\n",
    "    'feature_selection__max_features': [5, 10, 15],\n",
    "    'logistic__C': [0.1, 1, 10]\n",
    "  }\n",
    "}\n",
    "\n",
    "# Perform grid search for each model\n",
    "for name, param_grid in param_grids.items():\n",
    "  if name == 'Elastic Net Logistic Regression':\n",
    "    model = elastic_net_lr\n",
    "  elif name == 'Cost Sensitive Logistic Regression':\n",
    "    model = cost_sensitive_lr\n",
    "  elif name == 'Polynomial Logistic Regression':\n",
    "    model = polynomial_lr\n",
    "  elif name == 'Selected Features Logistic Regression':\n",
    "    model = selected_features_lr\n",
    "  \n",
    "  grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    refit=True\n",
    "  )\n",
    "  \n",
    "  grid_search.fit(X_train, y_train)\n",
    "  store_results(name, grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bada024",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Évaluation des classifieurs binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "168b75cd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'roc_plot' from 'utils' (/Users/mathisderenne/Documents/02 - Scolaire/M1 MIASHS/02 - Guillaume Mezler/Projet/src/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_plot, precision_recall_plot, table_report\n\u001b[1;32m      3\u001b[0m y_pred_weighted_knn \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      4\u001b[0m y_pred_proba_weighted_knn \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:,\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'roc_plot' from 'utils' (/Users/mathisderenne/Documents/02 - Scolaire/M1 MIASHS/02 - Guillaume Mezler/Projet/src/utils.py)"
     ]
    }
   ],
   "source": [
    "from utils import roc_plot, precision_recall_plot, table_report\n",
    "\n",
    "y_pred_weighted_knn = model.predict(X_test)\n",
    "y_pred_proba_weighted_knn = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0d637",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "La [](#table_report_LR1) montre les résultats de la classification par le modèle de régression logistique. On observe que :\n",
    "\n",
    "- $83,04 \\%$ des *spams* sont correctement identifiés\n",
    "- $99,59 \\%$ des *hams* sont correctement identifiés\n",
    "- $96,88 \\%$ des observations classifiées en tant que *spam* sont des *spams*\n",
    "- $97,43 \\%$ des observations classifiées en tant que *ham* sont des *hams*\n",
    "- Le score F1 moyen pondéré est de $97,98 \\%$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c6fc3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "input_path": "src/template.ipynb",
   "output_path": "src_built/18 - segmentation.ipynb",
   "parameters": {
    "dataset": "segmentation"
   },
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
